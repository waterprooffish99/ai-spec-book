"use strict";(globalThis.webpackChunkai_spec_book=globalThis.webpackChunkai_spec_book||[]).push([[472],{2651:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>a,default:()=>p,frontMatter:()=>i,metadata:()=>s,toc:()=>l});const s=JSON.parse('{"id":"the-spec-driven-ai-engineer/chapter-5-deployment-and-feedback","title":"Chapter 5: Deployment & The Feedback Loop","description":"An AI agent running on your laptop is a prototype. A production-grade AI system is one that is deployed, scalable, and constantly improving. This final chapter covers the two critical, intertwined components of productionizing your agentic workflow: deploying it as a robust service and creating a feedback loop to iteratively improve its spec.","source":"@site/docs/the-spec-driven-ai-engineer/05-chapter-5-deployment-and-feedback.md","sourceDirName":"the-spec-driven-ai-engineer","slug":"/spec-driven-ai-engineer/deployment-and-feedback","permalink":"/ai-spec-book/spec-driven-ai-engineer/deployment-and-feedback","draft":false,"unlisted":false,"editUrl":"https://github.com/waterprooffish99/ai-spec-book/tree/main/docs/the-spec-driven-ai-engineer/05-chapter-5-deployment-and-feedback.md","tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"slug":"/spec-driven-ai-engineer/deployment-and-feedback","title":"Chapter 5: Deployment & The Feedback Loop"},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 4: Advanced Architectures - Subagents and Delegation","permalink":"/ai-spec-book/spec-driven-ai-engineer/advanced-architectures"},"next":{"title":"Tutorial - Extras","permalink":"/ai-spec-book/category/tutorial---extras"}}');var r=t(4848),o=t(8453);const i={slug:"/spec-driven-ai-engineer/deployment-and-feedback",title:"Chapter 5: Deployment & The Feedback Loop"},a=void 0,c={},l=[{value:"Part 1: Deployment with FastAPI",id:"part-1-deployment-with-fastapi",level:2},{value:"Structuring the FastAPI Application",id:"structuring-the-fastapi-application",level:3},{value:"Part 2: The Feedback Loop",id:"part-2-the-feedback-loop",level:2},{value:"Types of Feedback",id:"types-of-feedback",level:3},{value:"Closing the Loop",id:"closing-the-loop",level:3},{value:"Deploying the Book to GitHub Pages",id:"deploying-the-book-to-github-pages",level:2}];function d(e){const n={code:"code",em:"em",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsxs)(n.p,{children:["An AI agent running on your laptop is a prototype. A production-grade AI system is one that is deployed, scalable, and constantly improving. This final chapter covers the two critical, intertwined components of productionizing your agentic workflow: deploying it as a robust service and creating a feedback loop to iteratively improve its ",(0,r.jsx)(n.code,{children:"spec"}),"."]}),"\n",(0,r.jsx)(n.h2,{id:"part-1-deployment-with-fastapi",children:"Part 1: Deployment with FastAPI"}),"\n",(0,r.jsxs)(n.p,{children:['Your AI agent\'s "brain"\u2014the orchestrator loop that we designed\u2014needs to live inside a web server to be accessible by other applications (like a web front-end, a Slack bot, or another microservice). ',(0,r.jsx)(n.strong,{children:"FastAPI"})," is an excellent choice for this, as it's a modern, high-performance Python web framework that supports ",(0,r.jsx)(n.code,{children:"async"})," operations out of the box, which is perfect for long-running agent tasks."]}),"\n",(0,r.jsx)(n.h3,{id:"structuring-the-fastapi-application",children:"Structuring the FastAPI Application"}),"\n",(0,r.jsx)(n.p,{children:"Let's wrap the multi-agent orchestrator from the previous chapter in a FastAPI service."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"1. Install Libraries:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'pip install fastapi "uvicorn[standard]"\n'})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsxs)(n.strong,{children:["2. Create the FastAPI script (",(0,r.jsx)(n.code,{children:"main.py"}),"):"]})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from fastapi import FastAPI, BackgroundTasks\nfrom pydantic import BaseModel\nimport json\nimport time\n\n# --- Agentic Code (from Chapter 4, simplified) ---\n# In a real project, this would be in a separate \'agents\' module.\n\ndef invoke_research_agent(query: str) -> str:\n    """Simulates a time-consuming research task."""\n    time.sleep(3) # Simulate network/computation time\n    if "AAPL" in query and "revenue" in query:\n        return json.dumps({\n            "ticker": "AAPL",\n            "source": "Q4 2025 Report",\n            "key_finding": "Apple\'s Q4 revenue was $90.1 billion."\n        })\n    return json.dumps({"error": "Could not find specific data."})\n\ndef invoke_writer_agent(notes: str) -> str:\n    """Simulates the writer agent."""\n    time.sleep(1)\n    data = json.loads(notes)\n    if "key_finding" in data:\n        return f"According to the {data[\'source\']}, we found that {data[\'key_finding\']}"\n    return "Could not generate a report from the provided notes."\n\ndef run_orchestrator_task(user_prompt: str) -> str:\n    """The full, synchronous agent workflow."""\n    print(f"INFO: Running orchestrator for prompt: \'{user_prompt}\'")\n    research_notes = invoke_research_agent("AAPL Q4 revenue")\n    final_report = invoke_writer_agent(research_notes)\n    print(f"INFO: Orchestrator finished. Report: \'{final_report}\'")\n    return final_report\n\n# --- FastAPI Application ---\n\napp = FastAPI()\n\n# Pydantic models for request and response validation\nclass AgentRequest(BaseModel):\n    prompt: str\n\nclass AgentResponse(BaseModel):\n    status: str\n    report: str | None = None\n\n# In-memory "database" to store results of async tasks\ntask_results = {}\n\ndef background_agent_runner(task_id: str, prompt: str):\n    """A wrapper to run our agent and store the result."""\n    report = run_orchestrator_task(prompt)\n    task_results[task_id] = {"status": "completed", "report": report}\n\n\n@app.post("/generate-report", response_model=AgentResponse)\nasync def generate_report(request: AgentRequest, background_tasks: BackgroundTasks):\n    """\n    Asynchronous endpoint to trigger the agent workflow.\n    It starts the agent in the background and immediately returns a task ID.\n    """\n    task_id = f"task_{int(time.time())}"\n    task_results[task_id] = {"status": "in_progress", "report": None}\n    \n    # Run the time-consuming agent logic in the background\n    background_tasks.add_task(background_agent_runner, task_id, request.prompt)\n    \n    return {"status": f"Task {task_id} started. Check status endpoint for results."}\n\n@app.get("/report-status/{task_id}", response_model=AgentResponse)\nasync def get_report_status(task_id: str):\n    """Endpoint to check the status and get the result of a task."""\n    result = task_results.get(task_id, {"status": "not_found"})\n    return result\n\n'})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"3. Run the server:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"uvicorn main:app --reload\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Now you have a running API server on ",(0,r.jsx)(n.code,{children:"http://127.0.0.1:8000"}),". You can interact with it using a tool like ",(0,r.jsx)(n.code,{children:"curl"})," or a Python script:"]}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"POST"})," to ",(0,r.jsx)(n.code,{children:"/generate-report"})," to start the task."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"GET"})," from ",(0,r.jsx)(n.code,{children:"/report-status/{task_id}"})," to check on it and get the final report."]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:'This async, task-based pattern is essential for agentic systems, where a single "request" might take 30 seconds or more to complete.'}),"\n",(0,r.jsx)(n.h2,{id:"part-2-the-feedback-loop",children:"Part 2: The Feedback Loop"}),"\n",(0,r.jsxs)(n.p,{children:["Deployment is just the beginning. An agent's performance will drift, users will find edge cases, and new data will become available. A system for ",(0,r.jsx)(n.strong,{children:"collecting, analyzing, and acting on feedback"})," is the engine of iterative improvement in Spec-Driven Development."]}),"\n",(0,r.jsx)(n.h3,{id:"types-of-feedback",children:"Types of Feedback"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Explicit Feedback:"}),' Ask users directly. After displaying a result, show a simple "\ud83d\udc4d / \ud83d\udc4e" button. If they click "\ud83d\udc4e", open a small text box asking "What was wrong with this response?"']}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Implicit Feedback:"})," Track user behavior. If a user immediately re-phrases their query and tries again after getting a response, it's a strong signal the first response was poor."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Evaluation-driven Feedback:"}),' Periodically run your "Golden Set" (from Chapter 1) of evaluation examples against the deployed agent. If a prompt that used to work now fails, that\'s a regression that needs to be fixed.']}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"closing-the-loop",children:"Closing the Loop"}),"\n",(0,r.jsx)(n.p,{children:"All this collected feedback is gold. It is the input for the next iteration of your development cycle."}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Collect:"})," Store all feedback in a database. A simple schema might be: ",(0,r.jsx)(n.code,{children:"(timestamp, user_prompt, agent_response, feedback_score, feedback_text)"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Analyze:"})," Look for patterns in the feedback.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Are users consistently disliking answers about a specific topic? ",(0,r.jsx)(n.em,{children:"Maybe your RAG knowledge base is missing documents on that topic."})]}),"\n",(0,r.jsxs)(n.li,{children:["Is the agent failing to use the right tool for a certain kind of question? ",(0,r.jsx)(n.em,{children:"Maybe the tool's description in the agent's spec needs to be clearer."})]}),"\n",(0,r.jsxs)(n.li,{children:["Is the agent's tone wrong? ",(0,r.jsx)(n.em,{children:"Maybe the persona definition in the spec needs to be adjusted."})]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Refine the Spec:"})," This is the core of SDD. You use the analysis to update your specification document.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Old Spec:"})," ",(0,r.jsx)(n.code,{children:'"Tool: get_stock_price(ticker: str)"'})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Feedback:"})," ",(0,r.jsx)(n.em,{children:'"Agent fails to get prices for international stocks."'})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"New Spec:"})," ",(0,r.jsx)(n.code,{children:"\"Tool: get_stock_price(ticker: str, market: str = 'US')\""})," -> This leads to a change in the tool's implementation."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Redeploy:"})," Deploy the updated agent and measure the impact of your changes on the feedback metrics."]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["This cycle of ",(0,r.jsx)(n.strong,{children:"Deploy -> Collect -> Analyze -> Refine -> Redeploy"})," turns a static prototype into a living, learning system that gets progressively more aligned with its purpose."]}),"\n",(0,r.jsx)(n.h2,{id:"deploying-the-book-to-github-pages",children:"Deploying the Book to GitHub Pages"}),"\n",(0,r.jsx)(n.p,{children:"Finally, to share your knowledge, you can easily deploy this Docusaurus site."}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsxs)(n.strong,{children:["Set ",(0,r.jsx)(n.code,{children:"url"})," and ",(0,r.jsx)(n.code,{children:"baseUrl"})," in ",(0,r.jsx)(n.code,{children:"docusaurus.config.ts"}),":"]})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-typescript",children:"// docusaurus.config.ts\nconst config = {\n  // ...\n  url: 'https://<YOUR_GITHUB_USERNAME>.github.io',\n  baseUrl: '/<YOUR_REPOSITORY_NAME>/',\n  // ...\n};\n"})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsxs)(n.strong,{children:["Add a deployment script to ",(0,r.jsx)(n.code,{children:"package.json"}),":"]})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-json",children:'// package.json\n"scripts": {\n  "deploy": "docusaurus deploy"\n},\n'})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Push your code to a new GitHub repository."})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Run the deploy command:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"GIT_USER=<YOUR_GITHUB_USERNAME> npm run deploy\n"})}),"\n",(0,r.jsxs)(n.p,{children:["This command will build your site and push the static files to the ",(0,r.jsx)(n.code,{children:"gh-pages"})," branch of your repository, making it live."]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"By mastering deployment and feedback, you complete the journey from a conceptual idea to a robust, continuously improving AI-powered product."})]})}function p(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>i,x:()=>a});var s=t(6540);const r={},o=s.createContext(r);function i(e){const n=s.useContext(o);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:i(e.components),s.createElement(o.Provider,{value:n},e.children)}}}]);